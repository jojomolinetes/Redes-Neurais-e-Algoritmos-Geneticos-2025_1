{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a04e657b",
   "metadata": {},
   "source": [
    "# Quem classifica a classe classificadora?\n",
    "\n",
    "**Nome: Joana de Medeiros Oliveira Hulse Molinete**\n",
    "\n",
    "### Introdução:\n",
    "No presente notebook, busco construir, treinar e testar uma rede neural classificadora, utilizando de códigos de construção de uma rede neural em Python puro disponibilizado pelo professor discente Daniel Cassar. Pretendo enunciar as diferenças entre uma rede neural regressora e uma rede neural classificadora, implementando então uma nova função de perda, nova métrica de erro e alterando o processamento da última camada de neurônios, para que o output seja um valor que represente uma probabilidade de classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1ceeeb",
   "metadata": {},
   "source": [
    "### Importando as bibliotecas necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a378cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joana24003\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from graphviz import Digraph\n",
    "\n",
    "SEMENTE_ALEATORIA = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7616317",
   "metadata": {},
   "source": [
    "### Dataset e separação de dados:\n",
    "\n",
    "O dataset escolhido foi o Pima Indians Diabetes, disponível no Github, muito utilizado em problemas de classificação. Ele contém atributos numéricos e alvo binário, onde 1 significa \"tem diabetes\" e 0 significa \"não tem diabetes\". Dessa forma, como o target já está em formato binário, podemos apenas definir os atributos desejados. Os dados foram divididos em 80% para treinamento e 20% para testagem da rede neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a87c9c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=\"https://raw.githubusercontent.com/npradaschnor/Pima-Indians-Diabetes-Dataset/master/diabetes.csv\"\n",
    "dataset = pd.read_csv(url)\n",
    "FEATURES = [\"Glucose\", \"BloodPressure\", \"Insulin\", \"BMI\"]\n",
    "TARGET = [\"Outcome\"]\n",
    "\n",
    "df = dataset\n",
    "\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abc6857",
   "metadata": {},
   "source": [
    "Após separarmos um subconjunto de atributos relevantes (glicose, pressão sanguínea, insulina e IMC), devemos normalizá-los para um melhor desempenho e ajuste da rede. Faremos também a separação dos dados em conjuntos de treino (80%) e teste (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f58babe",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = df.index\n",
    "indices_treino, indices_teste = train_test_split(\n",
    "    indices, test_size = 0.2, random_state = SEMENTE_ALEATORIA\n",
    ")\n",
    "\n",
    "df_treino = df.loc[indices_treino]\n",
    "df_teste = df.loc[indices_teste]\n",
    "\n",
    "X_treino = df_treino.reindex(FEATURES, axis=1).values\n",
    "y_treino = df_treino.reindex(TARGET, axis=1).values.ravel()\n",
    "\n",
    "X_teste = df_teste.reindex(FEATURES, axis=1).values\n",
    "y_teste = df_teste.reindex(TARGET, axis=1).values.ravel()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_treino = scaler.fit_transform(X_treino) \n",
    "X_teste = scaler.transform(X_teste) # só transforma com base no treino para não ter vazamento de informação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3146392a",
   "metadata": {},
   "source": [
    "### Rede neural:\n",
    "\n",
    "Como dito anteriormente, a rede neural original foi disponibilizada pelo professor Daniel Cassar [1] e modificada para abranger problemas de classificação. As alterações consistem na implementação da função de perda \"cross_entropy\", que faz comparações entre as previsões da rede neural e o valor real, atribuindo pesos diferentes para cada erro de acordo com o quão a previsão se aproximou (ou afastou) do valor real. Além disso, dentro da classe Valor, foram implementados os métodos log(), que calcula o logaritmo natural da informação, e o método__rsub__() que calcula a subtração de um valor e uma instância da classe Valor começando da direita para a esquerda. Ambos os métodos foram utilizados na função de perda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c900a4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install graphviz\n",
    "from graphviz import Digraph\n",
    "\n",
    "def _tracar(folha):\n",
    "    \"\"\"Função modificada da criada por Andrej Karpathy para construção de grafo.\n",
    "\n",
    "    Referência: https://github.com/karpathy/micrograd\n",
    "\n",
    "    \"\"\"\n",
    "    vertices = set()\n",
    "    arestas = set()\n",
    "\n",
    "    def construir(v):\n",
    "        \"\"\"Função recursiva para traçar o grafo.\"\"\"\n",
    "        if v not in vertices:\n",
    "            vertices.add(v)\n",
    "            for progenitor in v.progenitor:\n",
    "                arestas.add((progenitor, v))\n",
    "                construir(progenitor)\n",
    "\n",
    "    construir(folha)\n",
    "\n",
    "    return vertices, arestas\n",
    "\n",
    "def plota_grafo(folha):\n",
    "    \"\"\"Função modificada da criada por Andrej Karpathy para construção de grafo.\n",
    "\n",
    "    Referência: https://github.com/karpathy/micrograd\n",
    "\n",
    "    \"\"\"\n",
    "    grafo = Digraph(format=\"svg\", graph_attr={\"rankdir\": \"LR\"})\n",
    "    vertices, arestas = _tracar(folha)\n",
    "\n",
    "    for v in vertices:\n",
    "        id_vertice = str(id(v))\n",
    "\n",
    "        if hasattr(v, \"rotulo\") and (hasattr(v, \"grad\")):\n",
    "            texto = \"{ \" + f\"{v.rotulo} | data {v.data:.3f} | grad {v.grad:.3f}\" + \" }\"\n",
    "\n",
    "        elif hasattr(v, \"rotulo\"):\n",
    "            texto = \"{ \" + f\"{v.rotulo} | data {v.data:.3f}\" + \" }\"\n",
    "\n",
    "        else:\n",
    "            texto = \"{ \" + f\"data {v.data:.3f}\" + \" }\"\n",
    "\n",
    "        grafo.node(name=id_vertice, label=texto, shape=\"record\")\n",
    "\n",
    "        if v.operador_mae:\n",
    "            grafo.node(name=id_vertice + v.operador_mae, label=v.operador_mae)\n",
    "            grafo.edge(id_vertice + v.operador_mae, id_vertice)\n",
    "\n",
    "    for vertice1, vertice2 in arestas:\n",
    "        grafo.edge(str(id(vertice1)), str(id(vertice2)) + vertice2.operador_mae)\n",
    "\n",
    "    return grafo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc75bf3c",
   "metadata": {},
   "source": [
    "### Função de perda Binary Cross-Entropy:\n",
    "\n",
    "Por se tratar de um problema de classificação, precisamos alterar a função de perda que penaliza nosso algoritmo. A função escolhida foi a *Binary Cross-Entropy*, que utiliza da fórmula abaixo [2][3] para calcular as penalizações da rede:"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "473ad594",
   "metadata": {},
   "source": [
    "![image-2.png](attachment:image-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bb8c44",
   "metadata": {},
   "source": [
    "Onde $n$ representa o número total de exemplos no dataset. No entanto, é necessário adicionarmos um valor muito baixo ($\\epsilon$) somando ao valor em que será aplicada a função logarítmica, para evitar que o log resulte em 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d256dbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "def binary_cross_entropy(y_true, y_pred): # NOVA FUNÇÃO!\n",
    "    \"\"\"Calcula a função de perda Binary Cross-Entropy Loss para redes neurais de classificação binária\"\"\"\n",
    "    eps = 1e-5  # evita log(0)\n",
    "    n = len(y_true)\n",
    "    erro_total = Valor(0)\n",
    "\n",
    "    for i in range(n):\n",
    "        y_p = y_pred[i]\n",
    "        log_loss = - (y_true[i] * (y_p+eps).log() + (1 - y_true[i]) * (1 - y_p + eps).log())\n",
    "        erro_total += log_loss\n",
    "\n",
    "    return erro_total / n\n",
    "    \n",
    "class Valor:\n",
    "    def __init__(self, data, progenitor=(), operador_mae=\"\", rotulo=\"\"):\n",
    "        self.data = data\n",
    "        self.progenitor = progenitor\n",
    "        self.operador_mae = operador_mae\n",
    "        self.rotulo = rotulo\n",
    "        self.grad = 0\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Valor(data={self.data})\"\n",
    "\n",
    "    def sig(self):\n",
    "        \"\"\"Realiza a operação: exp(self) / (exp(self) + 1)\"\"\"\n",
    "        if self.data >= 0:\n",
    "            z = math.exp(-self.data)\n",
    "            result = 1 / (1 + z)\n",
    "        else:\n",
    "            z = math.exp(self.data)\n",
    "            result = z / (1 + z)\n",
    "\n",
    "        resultado = Valor(result, (self,), \"sig\")\n",
    "\n",
    "        def propagar_sig():\n",
    "            sig_grad = resultado.data * (1 - resultado.data)\n",
    "            self.grad += resultado.grad * sig_grad\n",
    "\n",
    "        resultado.propagar = propagar_sig\n",
    "\n",
    "        return resultado\n",
    "        \n",
    "    \n",
    "    def log(self, base=math.e): # NOVO MÉTODO!\n",
    "        \"\"\"Realiza a operação: log(self)\"\"\"\n",
    "        progenitor = (self, )\n",
    "        data = math.log(self.data)\n",
    "        operador_mae = \"log\"\n",
    "        resultado = Valor(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_log():\n",
    "            self.grad += resultado.grad / self.data\n",
    "        \n",
    "        resultado.propagar = propagar_log\n",
    "        \n",
    "        return resultado\n",
    "        \n",
    "    def __add__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: self + outro_valor.\"\"\"\n",
    "        \n",
    "        if not isinstance(outro_valor, Valor):\n",
    "            outro_valor = Valor(outro_valor)\n",
    "            \n",
    "        progenitor = (self, outro_valor)\n",
    "        data = self.data + outro_valor.data\n",
    "        operador_mae = \"+\"\n",
    "        resultado = Valor(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_adicao():\n",
    "            self.grad += resultado.grad\n",
    "            outro_valor.grad += resultado.grad\n",
    "            \n",
    "        resultado.propagar = propagar_adicao\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __mul__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: self * outro_valor.\"\"\"\n",
    "        \n",
    "        if not isinstance(outro_valor, Valor):\n",
    "            outro_valor = Valor(outro_valor)\n",
    "            \n",
    "        progenitor = (self, outro_valor)\n",
    "        data = self.data * outro_valor.data\n",
    "        operador_mae = \"*\"\n",
    "        resultado = Valor(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_multiplicacao():\n",
    "            self.grad += resultado.grad * outro_valor.data # grad_filho * derivada filho em relação a mãe\n",
    "            outro_valor.grad += resultado.grad * self.data\n",
    "            \n",
    "        resultado.propagar = propagar_multiplicacao\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def exp(self):\n",
    "        \"\"\"Realiza a operação: exp(self)\"\"\"\n",
    "        progenitor = (self, )\n",
    "        data = math.exp(self.data)\n",
    "        operador_mae = \"exp\"\n",
    "        resultado = Valor(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_exp():\n",
    "            self.grad += resultado.grad * data \n",
    "        \n",
    "        resultado.propagar = propagar_exp\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __pow__(self, expoente):\n",
    "        \"\"\"Realiza a operação: self ** expoente\"\"\"\n",
    "        assert isinstance(expoente, (int, float))\n",
    "        progenitor = (self, )\n",
    "        data = self.data ** expoente\n",
    "        operador_mae = f\"**{expoente}\"\n",
    "        resultado = Valor(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_pow():\n",
    "            self.grad += resultado.grad * (expoente * self.data ** (expoente - 1))\n",
    "        \n",
    "        resultado.propagar = propagar_pow\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __truediv__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: self / outro_valor\"\"\"\n",
    "        return self * outro_valor ** (-1)\n",
    "    \n",
    "    def __neg__(self):\n",
    "        \"\"\"Realiza a operação: -self\"\"\"\n",
    "        return self * -1\n",
    "    \n",
    "    def __sub__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: self - outro_valor\"\"\"\n",
    "        return self + (-outro_valor)\n",
    "    \n",
    "    def __rsub__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: self - outro_valor\"\"\"\n",
    "        return outro_valor + (self * -1)\n",
    "    \n",
    "    def __radd__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: outro_valor + self\"\"\"\n",
    "        return self + outro_valor\n",
    "    \n",
    "    def __rmul__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: outro_valor * self\"\"\"\n",
    "        return self * outro_valor\n",
    "\n",
    "    def propagar(self):\n",
    "        pass\n",
    "    \n",
    "    def propagar_tudo(self):\n",
    "        \n",
    "        self.grad = 1\n",
    "        \n",
    "        ordem_topologica = []\n",
    "        \n",
    "        visitados = set()\n",
    "\n",
    "        def constroi_ordem_topologica(v):\n",
    "            if v not in visitados:\n",
    "                visitados.add(v)\n",
    "                for progenitor in v.progenitor:\n",
    "                    constroi_ordem_topologica(progenitor)\n",
    "                ordem_topologica.append(v)\n",
    "\n",
    "        constroi_ordem_topologica(self)\n",
    "        \n",
    "        for vertice in reversed(ordem_topologica):\n",
    "            vertice.propagar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "328b65f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuronio:\n",
    "    def __init__(self, num_dados_entrada):\n",
    "        self.vies = Valor(random.uniform(-1, 1))\n",
    "        \n",
    "        self.pesos = []\n",
    "        for i in range(num_dados_entrada):\n",
    "            self.pesos.append(Valor(random.uniform(-1, 1)))\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        \n",
    "        assert len(x) == len(self.pesos)\n",
    "        \n",
    "        soma = Valor(0)\n",
    "        for info_entrada, peso_interno in zip(x, self.pesos):\n",
    "            soma += info_entrada * peso_interno\n",
    "            \n",
    "        soma += self.vies  \n",
    "        dado_de_saida = soma.sig()\n",
    "\n",
    "        return dado_de_saida    \n",
    "    \n",
    "    def parametros(self):\n",
    "        return self.pesos + [self.vies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc82ac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Camada:\n",
    "    def __init__(self, num_neuronios, num_dados_entrada):\n",
    "        neuronios = []\n",
    "        \n",
    "        for i in range(num_neuronios):\n",
    "            neuronio = Neuronio(num_dados_entrada)\n",
    "            neuronios.append(neuronio)   \n",
    "            \n",
    "        self.neuronios = neuronios     \n",
    "        \n",
    "    def __call__(self, x):\n",
    "        dados_de_saida = []\n",
    "        \n",
    "        for neuronio in self.neuronios:\n",
    "            informacao = neuronio(x)\n",
    "            dados_de_saida.append(informacao)\n",
    "            \n",
    "        if len(dados_de_saida) == 1:\n",
    "            return dados_de_saida[0]\n",
    "        else:        \n",
    "            return dados_de_saida  \n",
    "    \n",
    "    def parametros(self):\n",
    "        params = []\n",
    "        \n",
    "        for neuronio in self.neuronios:\n",
    "            params_neuronio = neuronio.parametros()\n",
    "            params.extend(params_neuronio)\n",
    "        \n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4713d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, num_dados_entrada, num_neuronios_por_camada):\n",
    "        \n",
    "        percurso = [num_dados_entrada] + num_neuronios_por_camada\n",
    "        \n",
    "        camadas = []\n",
    "        \n",
    "        for i in range(len(num_neuronios_por_camada)):\n",
    "            camada = Camada(num_neuronios_por_camada[i], percurso[i])\n",
    "            camadas.append(camada)\n",
    "            \n",
    "        self.camadas = camadas\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for camada in self.camadas:\n",
    "            x = camada(x)\n",
    "        return x\n",
    "    \n",
    "    def parametros(self):\n",
    "        params = []\n",
    "        \n",
    "        for camada in self.camadas:\n",
    "            parametros_camada = camada.parametros()\n",
    "            params.extend(parametros_camada)\n",
    "            \n",
    "        return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bbf888",
   "metadata": {},
   "source": [
    "Definimos a arquitetura da rede neural tendo como entrada 4 valores ('Glucose', 'BloodPressure', 'BMI', 'Insulin') e contendo 3 camadas ocultas, as primeiras com 4 neurônios e a última com 3 neurônios. A saída é um único valor, já que se trata de uma rede neural classificadora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce76d381",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_treino\n",
    "\n",
    "NUM_DADOS_DE_ENTRADA = 4\n",
    "NUM_DADOS_DE_SAIDA = 1    \n",
    "CAMADAS_OCULTAS = [4, 3, 3]  \n",
    "\n",
    "arquitetura_da_rede = CAMADAS_OCULTAS + [NUM_DADOS_DE_SAIDA]\n",
    "\n",
    "minha_mlp = MLP(NUM_DADOS_DE_ENTRADA, arquitetura_da_rede)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c225c0",
   "metadata": {},
   "source": [
    "### Treinando a rede neural:\n",
    "\n",
    "Para o treinamento, utilizei o mesmo código que o dado no exemplo do professor discente, com 200 épocas e uma taxa de aprendizado de 0,01. Além disso, foi definido o método de classificação das previsões utilizando a lógica que se a porcentagem (em valor decimal) for maior ou igual do que 50% (0.5) de ter diabetes, classifica-se como 1 (\"tem diabetes\") e se for menor classifica-se como 0 (\"não tem diabetes\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22c6f565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "época: 0, loss: 0.7370, acurácia: 0.3469055374592834\n",
      "época: 10, loss: 0.7367, acurácia: 0.3469055374592834\n",
      "época: 20, loss: 0.7365, acurácia: 0.3469055374592834\n",
      "época: 30, loss: 0.7362, acurácia: 0.3469055374592834\n",
      "época: 40, loss: 0.7359, acurácia: 0.3469055374592834\n",
      "época: 50, loss: 0.7357, acurácia: 0.3469055374592834\n",
      "época: 60, loss: 0.7354, acurácia: 0.3469055374592834\n",
      "época: 70, loss: 0.7352, acurácia: 0.3469055374592834\n",
      "época: 80, loss: 0.7349, acurácia: 0.3469055374592834\n",
      "época: 90, loss: 0.7347, acurácia: 0.3469055374592834\n",
      "época: 99, loss: 0.7345, acurácia: 0.3469055374592834\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCAS = 200\n",
    "TAXA_DE_APRENDIZADO = 0.01\n",
    "\n",
    "for epoca in range(NUM_EPOCAS):\n",
    "    # forward pass\n",
    "    y_pred = []\n",
    "    for exemplo in X_treino:\n",
    "        previsao = minha_mlp(exemplo).sig()\n",
    "        y_pred.append(previsao)\n",
    "\n",
    "    # loss\n",
    "    loss = binary_cross_entropy(y_treino, y_pred)\n",
    "\n",
    "    # zero grad\n",
    "    for p in minha_mlp.parametros():\n",
    "        p.grad = 0\n",
    "\n",
    "    # backpropagation\n",
    "    loss.propagar_tudo()\n",
    "   \n",
    "    # atualiza parâmetros\n",
    "    for p in minha_mlp.parametros():\n",
    "        p.data = p.data - (p.grad * TAXA_DE_APRENDIZADO)\n",
    "        \n",
    "    # acurácia\n",
    "    if epoca % 10 == 0 or epoca == NUM_EPOCAS - 1:\n",
    "        y_pred_classes = []\n",
    "        for y in y_pred:\n",
    "            if y.sig().data >= 0.5:\n",
    "                y_pred_classes.append(1)\n",
    "            else:\n",
    "                y_pred_classes.append(0)\n",
    "        \n",
    "        acertos = 0\n",
    "        \n",
    "        for y_t, y_p in zip(y_treino, y_pred_classes):\n",
    "            if y_t == y_p:\n",
    "                acertos += 1\n",
    "            else:\n",
    "                continue\n",
    "        acuracia = acertos/len(y_treino)\n",
    "        print(f'época: {epoca}, loss: {loss.data:.4f}, acurácia: {acuracia}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf513b4b",
   "metadata": {},
   "source": [
    "### Métrica de acurácia:\n",
    "\n",
    "A métrica de análise utilizada foi a acurácia, onde se divide o número de previsões corretas pelo número total de previsões, tendo assim uma comparação entre os valores previstos e os valores reais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "008b81da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no teste: 0.6429\n"
     ]
    }
   ],
   "source": [
    "y_pred_teste = []\n",
    "for exemplo in X_teste:\n",
    "    previsao = minha_mlp(exemplo)\n",
    "    y_pred_teste.append(previsao)\n",
    "\n",
    "y_pred_classes = [1 if y.data >= 0.5 else 0 for y in y_pred_teste]\n",
    "acuracia_teste = accuracy_score(y_teste, y_pred_classes)\n",
    "print(f\"Acurácia no teste: {acuracia_teste:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6027485d",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "O objetivo de construir uma rede neural classificadora do zero em Python puro foi alcançado, apesar dos resultados não terem sido satisfatórios. Algumas modificações se fizeram importantes, visto que partimos de uma rede neural regressora disponibilizada na matéria de Redes Neurais e Algoritmos Genéticos, como a substituição da função de perda pela função de Entropia Binária Cruzada, o uso da acurácia como métrica de desempenho e a aplicação da função sigmoide na camada de saída para geração de probabilidades.\n",
    "\n",
    "Pude evidenciar não apenas a aplicabilidade de redes neurais em tarefas de classificação, mas também um entendimento mais profundo dos seus componentes fundamentais ao construir e treinar a rede passo a passo, sem o uso de bibliotecas prontas importadas do Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7450a3e",
   "metadata": {},
   "source": [
    "### Referências:\n",
    "\n",
    "[1] CASSAR, Daniel. Redes Neurais e Algoritmos Genéticos. 2025. ATP-303 NN 4.2 - Notebook MLP, material de aula.\n",
    "\n",
    "[2] Loss Functions in Deep Learning (Binary Cross-Entropy). Geeks for geeks, 2025. Disponível em: https://www.geeksforgeeks.org/loss-functions-in-deep-learning/ \n",
    "\n",
    "[3] SHAH, Deval. Understanding Binary Cross-Entropy and Log Loss for Effective Model Monitoring. Coralogix, 2023.  Disponível em: https://coralogix.com/ai-blog/understanding-binary-cross-entropy-and-log-loss-for-effective-model-monitoring/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
