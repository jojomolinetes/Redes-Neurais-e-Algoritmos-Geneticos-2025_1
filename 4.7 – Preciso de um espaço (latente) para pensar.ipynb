{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22ca7703",
   "metadata": {},
   "source": [
    "# 4.7 Preciso de um espaço (latente) para pensar\n",
    "\n",
    "**Nome: Joana de Medeiros Oliveira Hulse Molinete**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3512a95f",
   "metadata": {},
   "source": [
    "### Introdução:\n",
    "\n",
    "Um autocodificador é um tipo de arquitetura de rede neural projetada para compactar (codificar) eficientemente dados de entrada até suas características essenciais e então reconstruir (decodificar) a entrada original a partir dessa representação compactada.\n",
    "\n",
    "Autocodificadores são treinados para descobrir variáveis latentes dos dados de entrada: variáveis ocultas ou aleatórias que, apesar de não serem diretamente observáveis, informam fundamentalmente a forma como os dados são distribuídos. Coletivamente, as variáveis latentes de um determinado conjunto de dados de entrada são chamadas de espaço latente. Durante o treinamento, o autocodificador aprende quais variáveis latentes podem ser usadas para reconstruir os dados originais com mais precisão: essa representação do espaço latente, portanto, representa apenas as informações mais essenciais contidas na entrada original. Os codificadores descobrem as variáveis latentes ao passar os dados de entrada por um \"gargalo\" antes de chegarem ao decodificador. Isso força o codificador a aprender a extrair e passar para frente apenas as informações mais importantes para reconstruir a entrada original.\n",
    "\n",
    "Apesar de não precisarem de validação externa, autoencoders não podem ser classificados como modelos não-supervisionados, já que tem como objetivo a reconstrução da própria entrada, que também servem de comparação para a saída. Por isso, são classificados como modelos autossupervisionados — daí o nome \"autocodificador\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e130cb97",
   "metadata": {},
   "source": [
    "### Autoencoders Variacionais:\n",
    "\n",
    "Autocodificadores variacionais (VAEs) adaptam a arquitetura do autoencoder original para uso em tarefas generativas, onde o decodificador gera novas amostras de dados. Ao invés de reproduzir uma representação direta do espaço latente (como os encoders usuais), produz dois conjuntos de parâmetros: um de médias (μ) e um do logaritmo das variâncias (σ²). A representação latente (z) é amostrada dessa distribuição Gaussiana usando o truque de reparametrização, que separa a parte estocástica da parte determinística do cálculo.\n",
    "Para gerar uma nova amostra, o VAE amostra um vetor latente aleatório (ε) de dentro da distribuição Gaussiana — basicamente, seleciona um ponto de partida aleatório de dentro da distribuição normal — desloca-o pela média da distribuição latente (μ) e o dimensiona pela variância da distribuição latente (σ).\n",
    " \n",
    "Os VAEs aprendem a codificar aprendizados de recursos importantes a partir das entradas nos conjuntos de dados nos quais são treinados de uma forma flexível e aproximada, o que permite gerar novas amostras que se assemelham aos dados de treinamento originais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474b3ace",
   "metadata": {},
   "source": [
    "### Importando as bibliotecas necessárias e definindo os hiperparâmetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c087c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "entrada = 784 # 28x28 pixels\n",
    "num_classes = 10 # 0-9\n",
    "taxa_aprendizado = 0.001\n",
    "num_epocas = 30\n",
    "tamanho_lote = 100\n",
    "hidden_dim = 400 # n° de neurônios ocultos em cada camada\n",
    "latent_dim = 200 # tamanho do vetor z compactado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ae312b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mnist_transform = transforms.Compose([transforms.ToTensor(),])\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} # key arguments\n",
    "\n",
    "dataset_treino = datasets.MNIST(root='dataset/', download=True, train=True, transform=mnist_transform)\n",
    "carrega_dados_treino = DataLoader(dataset=dataset_treino, batch_size=tamanho_lote, shuffle=True, **kwargs) # aqui **kwargs vai desempacotar o dicionário\n",
    "\n",
    "dataset_teste = datasets.MNIST(root='dataset/', download=True, train=False, transform=mnist_transform)\n",
    "carrega_dados_teste = DataLoader(dataset=dataset_teste, batch_size=tamanho_lote, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b785deed",
   "metadata": {},
   "source": [
    "### Bloco encoder:\n",
    "\n",
    "Aqui, definimos a arquitetura da parte codificadora da nossa rede, que recebe as entradas e codifica sua representação nas camadas totalmente conectadas. Usamos a função LeakyReLU ao invés da ReLU, pois ela impede que o gradiente zere quando o neurônio recebe um valor negativo. Precisamos modelar uma distribuição gaussiana N(μ,σ^2), então precisamos de dois vetores de saída: a média e a variância da distribuição. Aqui, trabalhamos com o logaritmo da variância, pois fornece maior estabilidade para a rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7623833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        # aplicando camadas lineares para compactar os vetores:\n",
    "        self.FC_input = nn.Linear(input_dim, hidden_dim) # camada fully-connected que comprime os dados de entrada (vetor de 784 valores) nas camadas ocultas (vetor de 400 valores)\n",
    "        self.FC_input2 = nn.Linear(hidden_dim, hidden_dim) # repete o processo da primeira camada fully-connected, mas dessa vez mantendo a dimensão para aumentar a profundidade\n",
    "    \n",
    "        self.FC_mean =nn.Linear(hidden_dim, latent_dim) # gera o vetor de médias \n",
    "        self.FC_var = nn.Linear(hidden_dim, latent_dim) # gera o logaritmo das variâncias\n",
    "        \n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2) # se a entrada for positiva a informação passa igual, se for negativa passa apenas 20% (slope = 0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z_ = self.LeakyReLU(self.FC_input(x))\n",
    "        z_ = self.LeakyReLU(self.FC_input2(z_))\n",
    "        mean = self.FC_mean(z_) # projeta o vetor z (hidden_dim) em um vetor de médias de dimensão latent_dim (200 valores)\n",
    "        log_var = self.FC_var(z_) # projeta o vetor z (hidden_dim) em um vetor do log-variância de dimensão latent_dim (200 valores)\n",
    "        \n",
    "        return mean, log_var    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57fdd78",
   "metadata": {},
   "source": [
    "### Bloco decoder:\n",
    "\n",
    "Agora que definimos a codificação, vamos definir como funcionará o decodificador, que vai receber como entrada a saída comprimida da camada de amostragem e reconstruir a imagem original tendo como ponto de partida o vetor z.\n",
    "Para descomprimir os dados, aplicamos uma função sigmoidal em cada componente de x reconstruído, projetando o valor entre 0 e 1, para que a função de perda (Binary Cross-Entropy) possa interpretar como probabilidades futuramente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "129ac8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.FC_hidden = nn.Linear(latent_dim, hidden_dim) # expande a saída do encoder (200 valores) de volta para um vetor de 400 valores\n",
    "        self.FC_hidden2 = nn.Linear(hidden_dim, hidden_dim) # 400 -> 400 + LeakyReLU\n",
    "        self.FC_output = nn.Linear(hidden_dim, output_dim) # gera o vetor reconstruído de x (400 -> 784)\n",
    "        \n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.LeakyReLU(self.FC_hidden(x))\n",
    "        z = self.LeakyReLU(self.FC_hidden2(z))\n",
    "        \n",
    "        x_reconstruido = torch.sigmoid(self.FC_output(z)) # garante que x_reconstruído siga uma distribuição entre 0 e 1\n",
    "        return x_reconstruido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08e46c9",
   "metadata": {},
   "source": [
    "### Conectando nosso modelo VAE:\n",
    "\n",
    "Agora que definimos as duas partes principais de uma rede autocodificadora, podemos combiná-las em um modelo completo. Também utilizaremos o truque de reparametrização aqui, permitindo que os gradientes fluam através das operações de amostragem.\n",
    "Queremos que o vetor z siga uma distribuição normal N(μ,σ²), e que ainda nos permita calcular os gradientes (ou seja, mantendo a diferenciabilidade do modelo). Para isso, aplicamos o truque de reparametrização, que basicamente move a variável aleatória (epsilon) para fora da operação de amostragem da distribuição. Assim, mesmo incorporando um elemento estocástico ainda conseguimos propagar os gradientes dos parâmetros, porque eles não dependem do ruído criado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62b2c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, Encoder, Decoder):\n",
    "        super(VAE, self).__init__()\n",
    "        self.Encoder = Encoder\n",
    "        self.Decoder = Decoder\n",
    "        \n",
    "    def reparametrizacao(self, mean, var):\n",
    "        epsilon = torch.randn_like(var).to(device) # cria um tensor de ruído com a mesma forma de (var), de onde amostra o epsilon\n",
    "        z = mean + (var * epsilon) # reparametrização\n",
    "        return z\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean, log_var = self.Encoder(x)\n",
    "        std = torch.exp(0.5 * log_var) # transforma a variância em desvio padrão\n",
    "        z = self.reparametrizacao(mean, std) # aplica a reparametrização\n",
    "        x_reconstruido = self.Decoder(z)\n",
    "        return x_reconstruido, mean, log_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4221a7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea732436",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_dim = entrada, hidden_dim = hidden_dim, latent_dim = latent_dim)\n",
    "decoder = Decoder(latent_dim = latent_dim, hidden_dim = hidden_dim, output_dim = entrada)\n",
    "minha_vae = VAE(Encoder = encoder, Decoder = decoder).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96618398",
   "metadata": {},
   "source": [
    "### Função de perda: Binary Cross-Entropy\n",
    "\n",
    "Utilizar a função Binary Cross-Entropy (BCE) nos permite medir a qualidade de reconstrução da nossa rede, ou seja, quão parecido está a saída (x_reconstruído) da entrada (x), somando o erro em cada pixel. Já a divergência de Kullback-Leibler (KL divergence ou entropia relativa) é uma medida da diferença entre duas distribuições, que indica quanta informação foi perdida quando tentamos aproximar um valor Q dado P (um valor qualquer). Quando temos uma KLD próxima a 0, podemos afirmar que as distribuições P e Q são muito parecidas, e quanto mais próximo de 1 for o valor de KLD mais as distribuições se comportam de forma diferente entre si. Resumindo, o KLD quantifica o desvio entre a distribuição latente e a distribuição normal N(0,I)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42513f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BCE_loss = nn.BCELoss()\n",
    "\n",
    "def binary_cross_entropy_treino(x, x_reconstruido, mean, log_var):\n",
    "    reconstruction_loss = nn.functional.binary_cross_entropy(x_reconstruido, x, reduction='sum') # soma os erros de todos os pixels\n",
    "    KL_divergence = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp()) # mede a divergência entre a média e variância quando comparada com uma distribuição normal\n",
    "    \n",
    "    return reconstruction_loss + KL_divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835efa70",
   "metadata": {},
   "source": [
    "### Otimizador Adam\n",
    "\n",
    "O otimizador Adam [6] (Adaptive Moment Estimation) funciona com base em dois processos de otimização: o de descida de gradiente com operador momentum [8] e RMSprop (Propagação da Raiz Quadrática Média), que aplica um escalonamento adaptativo nos pesos calculando a média móvel ponderada exponencialmente dos gradientes quadrados. Combinando os dois, o otimizador ADAM ajusta a taxa de aprendizado de cada peso com base na média e variação dos gradientes. É muito vantajoso utilizar o ADAM como otimizador para autoencoders variacionais por lidar bem com gradientes de variâncias que podem ter escalas diferentes e com a diferença estocástica entre as atualizações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01f85c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  torch.optim import Adam\n",
    "\n",
    "otimizador = Adam(minha_vae.parameters(), lr = taxa_aprendizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05abe06d",
   "metadata": {},
   "source": [
    "### Treinando a rede neural:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cac92ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Começando o treinamento...\n",
      "Época: 1 completa! Perda média: 173.89463185713169\n",
      "Época: 2 completa! Perda média: 129.10586071186353\n",
      "Época: 3 completa! Perda média: 116.98578408675918\n",
      "Época: 4 completa! Perda média: 112.44347905689169\n",
      "Época: 5 completa! Perda média: 109.88333059982784\n",
      "Época: 6 completa! Perda média: 108.18995092732679\n",
      "Época: 7 completa! Perda média: 107.03088493843906\n",
      "Época: 8 completa! Perda média: 106.08922859714107\n",
      "Época: 9 completa! Perda média: 105.41410265481532\n",
      "Época: 10 completa! Perda média: 104.86660885003651\n",
      "Época: 11 completa! Perda média: 104.38247373552275\n",
      "Época: 12 completa! Perda média: 103.9394722975793\n",
      "Época: 13 completa! Perda média: 103.4974794090411\n",
      "Época: 14 completa! Perda média: 103.19715862700856\n",
      "Época: 15 completa! Perda média: 102.78267953098914\n",
      "Época: 16 completa! Perda média: 102.40334980501356\n",
      "Época: 17 completa! Perda média: 102.17235496661102\n",
      "Época: 18 completa! Perda média: 101.9453091578412\n",
      "Época: 19 completa! Perda média: 101.73491781549978\n",
      "Época: 20 completa! Perda média: 101.56547297253235\n",
      "Época: 21 completa! Perda média: 101.30917386725271\n",
      "Época: 22 completa! Perda média: 101.19724566986645\n",
      "Época: 23 completa! Perda média: 101.06072996008973\n",
      "Época: 24 completa! Perda média: 100.9245517268364\n",
      "Época: 25 completa! Perda média: 100.77668053526712\n",
      "Época: 26 completa! Perda média: 100.65689133582012\n",
      "Época: 27 completa! Perda média: 100.48645714863314\n",
      "Época: 28 completa! Perda média: 100.43337623252296\n",
      "Época: 29 completa! Perda média: 100.35847662771286\n",
      "Época: 30 completa! Perda média: 100.21093715763251\n",
      "Processamento finalizado!\n"
     ]
    }
   ],
   "source": [
    "print(\"Começando o treinamento...\")\n",
    "minha_vae.train()\n",
    "\n",
    "for epoca in range(num_epocas):\n",
    "    loss_total = 0\n",
    "    \n",
    "    for batch_index, (x, _) in enumerate(carrega_dados_treino):\n",
    "        x = x.view(tamanho_lote, entrada) # achata a imagem\n",
    "        x = x.to(device)\n",
    "        \n",
    "        # zero grad:\n",
    "        otimizador.zero_grad()\n",
    "        \n",
    "        # forward pass:\n",
    "        x_reconstruido, mean, log_var = minha_vae(x)\n",
    "        \n",
    "        # loss:\n",
    "        loss = binary_cross_entropy_treino(x, x_reconstruido, mean, log_var)\n",
    "        loss_total += loss.item()\n",
    "        \n",
    "        # backpropagation:\n",
    "        loss.backward()\n",
    "        \n",
    "        # atualiza parâmetros:\n",
    "        otimizador.step()\n",
    "        \n",
    "    print(f'Época: {epoca +1} completa!', f\"Perda média: {loss_total / (batch_index * tamanho_lote)}\")\n",
    "    \n",
    "print(\"Processamento finalizado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba50f58",
   "metadata": {},
   "source": [
    "### Testando nossa rede neural:\n",
    "\n",
    "Diferente do treino, no teste nós usamos a função de perda BCE configurada com um cálculo de redução de média (reduction = \"mean\"), por dois motivos principais: primeiro porque nos permite uma maior flexibilidade de interpretação, tanto em quesito de comparação entre os exemplos de teste e o treino, quanto entre modelos; outro motivo é a escala em que colocamos a redução, que nesse caso é o erro médio por pixel e por exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4349b75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy_teste(x, x_reconstruido, mean, log_var):\n",
    "    reproduction_loss = nn.functional.binary_cross_entropy(x_reconstruido, x, reduction='mean') # faz a média dos erros de todos os pixels\n",
    "    kld = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp()) # mede a divergência da distribuição normal da média e variância para N(0, 1)\n",
    "    \n",
    "    return reproduction_loss, kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce0e64a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No teste obtivemos como BCE médio: 0.0990 e como KLD médio: 22.7309\n"
     ]
    }
   ],
   "source": [
    "minha_vae.eval()\n",
    "\n",
    "bce_total = 0\n",
    "kld_total = 0\n",
    "batches = 0\n",
    "\n",
    "batch_to_plot = None\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, _ in carrega_dados_teste:\n",
    "        # achatando e enviando para GPU:\n",
    "        x = x.view(x.size(0), -1).to(device)\n",
    "        \n",
    "        # forward pass:\n",
    "        x_reconstruido, mean, log_var = minha_vae(x)\n",
    "        \n",
    "        # reconstrução e KLD médios:\n",
    "        rep_loss, kld = binary_cross_entropy_teste(x, x_reconstruido, mean, log_var)\n",
    "        kld = kld / x.size(0)\n",
    "        \n",
    "        bce_total += rep_loss.item()\n",
    "        kld_total += kld.item()\n",
    "        batches += 1\n",
    "        \n",
    "        if batch_to_plot is None:\n",
    "            batch_to_plot = (x.cpu(), x_reconstruido.cpu())\n",
    "        \n",
    "bce_medio = bce_total / batches\n",
    "kld_medio = kld_total / batches\n",
    "\n",
    "print(f\"No teste obtivemos como BCE médio: {bce_medio:.4f} e como KLD médio: {kld_medio:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4457cf7d",
   "metadata": {},
   "source": [
    "### Visualizando:\n",
    "\n",
    "Para fins de comparação, vamos plotar nossas imagens originais do MNIST com as saídas do modelo, ou seja, as reconstruções obtidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02a30890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1350x300 with 18 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "originais, reconstrucoes = batch_to_plot # tupla com dois tensores\n",
    "\n",
    "originais = originais.view(-1, 1, 28, 28)\n",
    "reconstrucoes = reconstrucoes.view(-1, 1, 28, 28)\n",
    "\n",
    "n = 9\n",
    "fig, axes = plt.subplots(2, n, figsize=(n*1.5, 3))\n",
    "for i in range(n):\n",
    "    axes[0, i].imshow(originais[i].squeeze(), cmap='gray', interpolation='none')\n",
    "    axes[0, i].axis('off')\n",
    "    axes[1, i].imshow(reconstrucoes[i].squeeze(), cmap='gray', interpolation='none')\n",
    "    axes[1, i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db585424",
   "metadata": {},
   "source": [
    "### Conclusão:\n",
    "\n",
    "Ao longo da atividade, foram abordados conceitos fundamentais sobre autoencoders, usados para a construção da sua arquitetura e aplicação em dados reais, com um destaque nos autoencoders Variacionais, uma extensão dos autoencoders tradicionais que foram capazes de gerar novas amostras de dados a partir da distribuição latente aprendida, como observado no exemplo visual. \n",
    "\n",
    "A visualização das imagens reconstruídas permitiu validar qualitativamente o funcionamento do modelo, conseguimos observar que as reconstruções obtidas pela VAE preservaram as características principais das imagens originais, o que evidencia que nossa rede aprendeu uma representação significativa do espaço latente. Aplicamos a divergência de Kullback-Leibler e o truque de reparametrização como soluções para os problemas do balanceamento entre a qualidade da reconstrução e a regularização do espaço latente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1536633",
   "metadata": {},
   "source": [
    "### Referências:\"\n",
    "\n",
    "[1] BERGMANN, Dave; STRYKER, Cole. What is an autoencoder? IBM, 2023. Disponível em: https://www.ibm.com/think/topics/autoencoder.\n",
    "\n",
    "[2] IPPOLITO, Pier Paolo. Introduction to Autoencoders: From The Basics to Advanced Applications in PyTorch. Geeks for geeks, 2023. Disponível em: https://www.datacamp.com/tutorial/introduction-to-autoencoders.\n",
    "\n",
    "[3] Variacional Autoencoders. Geeks for geeks, 2025. Disponível em: https://www.geeksforgeeks.org/variational-autoencoders/.\n",
    "\n",
    "[4] NLP From Scratch: Translation with a Sequence to Sequence Network and Attention. Pytorch Tutorials, 2017. Disponível em: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#exercises.\n",
    "\n",
    "[5] JONES, Llion. The reparameterization trick. Medium, 2017. Disponível em: https://medium.com/@llionj/the-reparameterization-trick-4ff30fe92954. \n",
    "\n",
    "[6] What is Adam Optimizer? Geeks for geeks, 2025. Disponível em: https://www.geeksforgeeks.org/adam-optimizer/.\n",
    "\n",
    "[7] MOLINETE, Joana. Notebook 4.5 \"Um momento, por favor!\" Otimizador gradient descent with momentum, 2025.\n",
    "\n",
    "[8] Many ways to plot images. Dcoumentação Matplotlib. Disponível em: https://matplotlib.org/stable/gallery/images_contours_and_fields/image_demo.html.\n",
    "\n",
    "[9] Create multiple subplots using plt.subplots. Documentação Matplotlib. Disponível em: https://matplotlib.org/stable/gallery/subplots_axes_and_figures/subplots_demo.html."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
